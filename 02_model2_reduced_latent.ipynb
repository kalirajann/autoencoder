{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 2: Modified Autoencoder (Reduced Latent Space)\n",
        "\n",
        "This notebook implements a **modified autoencoder** with **reduced latent dimension** compared to Model 1.\n",
        "\n",
        "**Key Modification:**\n",
        "- **Latent Dimension:** Reduced from 64 to **32**\n",
        "\n",
        "**Architecture:**\n",
        "- **Encoder:** 784 → 256 → 128 → 64 → **32** (latent)\n",
        "- **Decoder:** **32** (latent) → 64 → 128 → 256 → 784\n",
        "- **Optimizer:** RMSprop (lr=0.001) - same as Model 1\n",
        "- **Loss:** Mean Squared Error - same as Model 1\n",
        "- **Training:** 20 epochs, batch_size=128 - same as Model 1\n",
        "\n",
        "**Expected Results:**\n",
        "- Higher reconstruction loss due to increased information compression\n",
        "- More reconstruction artifacts (blurriness, loss of fine details)\n",
        "- Demonstrates the **compression vs. quality trade-off**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Preprocess Fashion-MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Fashion-MNIST dataset\n",
        "print(\"Loading Fashion-MNIST dataset...\")\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten input images for dense autoencoder\n",
        "x_train_flat = x_train.reshape((-1, 28 * 28))\n",
        "x_test_flat = x_test.reshape((-1, 28 * 28))\n",
        "\n",
        "print(f\"Training samples: {x_train_flat.shape[0]}\")\n",
        "print(f\"Test samples: {x_test_flat.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build Autoencoder Architecture (Reduced Latent Dimension)\n",
        "\n",
        "**MODIFICATION:** Reduced latent dimension from 64 to 32. This forces the bottleneck to compress 784 pixels into only 32 dimensions, increasing information loss. The model must discard more details to fit the essential information into the smaller space, resulting in blurrier reconstructions with more artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the autoencoder architecture (same as Model 1, but with reduced latent dimension)\n",
        "input_dim = 28 * 28\n",
        "# MODIFICATION: Reduced latent dimension from 64 to 32\n",
        "# This forces the bottleneck to compress 784 pixels into only 32 dimensions,\n",
        "# increasing information loss. The model must discard more details to fit\n",
        "# the essential information into the smaller space, resulting in blurrier\n",
        "# reconstructions with more artifacts.\n",
        "latent_dim = 32  # Reduced from 64 in Model 1\n",
        "\n",
        "# Encoder (architecture identical to Model 1)\n",
        "encoder_input = Input(shape=(input_dim,), name='encoder_input')\n",
        "x = Dense(256, activation='relu', name='enc_dense_1')(encoder_input)\n",
        "x = Dense(128, activation='relu', name='enc_dense_2')(x)\n",
        "x = Dense(64, activation='relu', name='enc_dense_3')(x)\n",
        "latent = Dense(latent_dim, activation='relu', name='latent')(x)\n",
        "\n",
        "encoder = Model(inputs=encoder_input, outputs=latent, name='encoder')\n",
        "\n",
        "# Decoder (architecture identical to Model 1)\n",
        "decoder_input = Input(shape=(latent_dim,), name='decoder_input')\n",
        "x = Dense(64, activation='relu', name='dec_dense_1')(decoder_input)\n",
        "x = Dense(128, activation='relu', name='dec_dense_2')(x)\n",
        "x = Dense(256, activation='relu', name='dec_dense_3')(x)\n",
        "decoder_output = Dense(input_dim, activation='sigmoid', name='decoder_output')(x)\n",
        "\n",
        "decoder = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "\n",
        "# Autoencoder: encoder + decoder\n",
        "ae_input = encoder_input\n",
        "ae_output = decoder(encoder(ae_input))\n",
        "autoencoder = Model(inputs=ae_input, outputs=ae_output, name='autoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile model (same optimizer and loss as Model 1)\n",
        "optimizer = RMSprop(learning_rate=0.001)  # same as Model 1\n",
        "loss_fn = MeanSquaredError()  # reconstruction loss\n",
        "autoencoder.compile(optimizer=optimizer, loss=loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print model summaries\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Encoder Summary:\")\n",
        "print(\"=\" * 50)\n",
        "encoder.summary()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Decoder Summary:\")\n",
        "print(\"=\" * 50)\n",
        "decoder.summary()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Autoencoder Summary:\")\n",
        "print(\"=\" * 50)\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model (same epochs and batch size as Model 1)\n",
        "epochs = 20  # same as Model 1\n",
        "batch_size = 128  # same as Model 1\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Training Autoencoder...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "history = autoencoder.fit(\n",
        "    x_train_flat, x_train_flat,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    validation_data=(x_test_flat, x_test_flat),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Loss per Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print training loss per epoch\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Training Loss per Epoch:\")\n",
        "print(\"=\" * 50)\n",
        "for epoch, loss in enumerate(history.history['loss'], start=1):\n",
        "    print(f\"Epoch {epoch}: {loss:.6f}\")\n",
        "\n",
        "# Final training loss\n",
        "final_train_loss = history.history['loss'][-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Evaluating on test set...\")\n",
        "print(\"=\" * 50)\n",
        "test_loss = autoencoder.evaluate(x_test_flat, x_test_flat, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Reconstruct Test Images\n",
        "\n",
        "Using the same 5 test image indices (0, 1, 2, 3, 4) as Model 1 for direct comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reconstruct test images (using same indices as Model 1)\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Reconstructing test images...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Select exactly 5 test images (same indices as Model 1: 0, 1, 2, 3, 4)\n",
        "n_images = 5\n",
        "indices = [0, 1, 2, 3, 4]\n",
        "test_samples = x_test_flat[indices]\n",
        "reconstructed = autoencoder.predict(test_samples, verbose=0)\n",
        "\n",
        "# Reshape for saving\n",
        "originals = test_samples.reshape((n_images, 28, 28))\n",
        "recos = reconstructed.reshape((n_images, 28, 28))\n",
        "\n",
        "# Ensure output directory exists\n",
        "output_dir = \"reconstructions\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"\\nSelected test image indices:\")\n",
        "for idx in indices:\n",
        "    print(f\"  Index: {idx}\")\n",
        "\n",
        "# Save images with Model 2 naming convention\n",
        "# Note: We expect more reconstruction artifacts due to reduced latent space\n",
        "print(\"\\nSaving images...\")\n",
        "for i in range(n_images):\n",
        "    # Save reconstructed images with Model 2 naming\n",
        "    reco_path = os.path.join(output_dir, f\"reconstructed_model2_{i+1}.png\")\n",
        "    \n",
        "    # Reconstructed image (with expected artifacts from information compression)\n",
        "    img2 = (np.clip(recos[i], 0, 1) * 255).astype('uint8')\n",
        "    Image.fromarray(img2, mode='L').save(reco_path)\n",
        "    \n",
        "    print(f\"  Saved: {reco_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print final model outputs\n",
        "print(\"\\n----------------------------------------------\")\n",
        "print(\"MODEL 2: MODIFIED AUTOENCODER (REDUCED LATENT SPACE)\")\n",
        "print(\"----------------------------------------------\")\n",
        "print(f\"Latent Dimension Used: {latent_dim}\")\n",
        "print(f\"Final Training Loss: {final_train_loss:.6f}\")\n",
        "print(f\"Final Test Reconstruction Loss: {test_loss:.6f}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
