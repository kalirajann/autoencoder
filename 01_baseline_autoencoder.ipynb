{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model 1: Baseline Autoencoder (Textbook Version)\n",
        "\n",
        "This notebook implements the **baseline autoencoder** from *Generative Deep Learning, 2nd Edition* (Chapter 3).\n",
        "\n",
        "**Architecture:**\n",
        "- **Encoder:** 784 → 256 → 128 → 64 → **64** (latent)\n",
        "- **Decoder:** **64** (latent) → 64 → 128 → 256 → 784\n",
        "- **Latent Dimension:** 64\n",
        "- **Optimizer:** RMSprop (lr=0.001)\n",
        "- **Loss:** Mean Squared Error\n",
        "- **Training:** 20 epochs, batch_size=128\n",
        "\n",
        "**Reference:** [autoencoder.ipynb](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/03_vae/01_autoencoder/autoencoder.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Preprocess Fashion-MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Fashion-MNIST dataset\n",
        "print(\"Loading Fashion-MNIST dataset...\")\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten input images for dense autoencoder\n",
        "x_train_flat = x_train.reshape((-1, 28 * 28))\n",
        "x_test_flat = x_test.reshape((-1, 28 * 28))\n",
        "\n",
        "print(f\"Training samples: {x_train_flat.shape[0]}\")\n",
        "print(f\"Test samples: {x_test_flat.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build Autoencoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the autoencoder architecture (exactly as textbook)\n",
        "input_dim = 28 * 28\n",
        "latent_dim = 64  # same latent dimension as in the notebook\n",
        "\n",
        "# Encoder\n",
        "encoder_input = Input(shape=(input_dim,), name='encoder_input')\n",
        "x = Dense(256, activation='relu', name='enc_dense_1')(encoder_input)\n",
        "x = Dense(128, activation='relu', name='enc_dense_2')(x)\n",
        "x = Dense(64, activation='relu', name='enc_dense_3')(x)\n",
        "latent = Dense(latent_dim, activation='relu', name='latent')(x)\n",
        "\n",
        "encoder = Model(inputs=encoder_input, outputs=latent, name='encoder')\n",
        "\n",
        "# Decoder\n",
        "decoder_input = Input(shape=(latent_dim,), name='decoder_input')\n",
        "x = Dense(64, activation='relu', name='dec_dense_1')(decoder_input)\n",
        "x = Dense(128, activation='relu', name='dec_dense_2')(x)\n",
        "x = Dense(256, activation='relu', name='dec_dense_3')(x)\n",
        "decoder_output = Dense(input_dim, activation='sigmoid', name='decoder_output')(x)\n",
        "\n",
        "decoder = Model(inputs=decoder_input, outputs=decoder_output, name='decoder')\n",
        "\n",
        "# Autoencoder: encoder + decoder\n",
        "ae_input = encoder_input\n",
        "ae_output = decoder(encoder(ae_input))\n",
        "autoencoder = Model(inputs=ae_input, outputs=ae_output, name='autoencoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile model\n",
        "optimizer = RMSprop(learning_rate=0.001)  # same as notebook\n",
        "loss_fn = MeanSquaredError()  # reconstruction loss\n",
        "autoencoder.compile(optimizer=optimizer, loss=loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print model summaries\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Encoder Summary:\")\n",
        "print(\"=\" * 50)\n",
        "encoder.summary()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Decoder Summary:\")\n",
        "print(\"=\" * 50)\n",
        "decoder.summary()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Autoencoder Summary:\")\n",
        "print(\"=\" * 50)\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "epochs = 20  # as in the notebook\n",
        "batch_size = 128  # as in the notebook\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Training Autoencoder...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "history = autoencoder.fit(\n",
        "    x_train_flat, x_train_flat,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    validation_data=(x_test_flat, x_test_flat),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Loss per Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print training loss per epoch\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Training Loss per Epoch:\")\n",
        "print(\"=\" * 50)\n",
        "for epoch, loss in enumerate(history.history['loss'], start=1):\n",
        "    print(f\"Epoch {epoch}: {loss:.6f}\")\n",
        "\n",
        "# Final training loss\n",
        "final_train_loss = history.history['loss'][-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Evaluating on test set...\")\n",
        "print(\"=\" * 50)\n",
        "test_loss = autoencoder.evaluate(x_test_flat, x_test_flat, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Reconstruct Test Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reconstruct test images\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Reconstructing test images...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Select exactly 5 test images (indices 0, 1, 2, 3, 4)\n",
        "n_images = 5\n",
        "indices = [0, 1, 2, 3, 4]\n",
        "test_samples = x_test_flat[indices]\n",
        "reconstructed = autoencoder.predict(test_samples, verbose=0)\n",
        "\n",
        "# Reshape for saving\n",
        "originals = test_samples.reshape((n_images, 28, 28))\n",
        "recos = reconstructed.reshape((n_images, 28, 28))\n",
        "\n",
        "# Ensure output directory exists\n",
        "output_dir = \"reconstructions\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"\\nSelected test image indices:\")\n",
        "for idx in indices:\n",
        "    print(f\"  Index: {idx}\")\n",
        "\n",
        "# Save images\n",
        "print(\"\\nSaving images...\")\n",
        "for i in range(n_images):\n",
        "    orig_path = os.path.join(output_dir, f\"original_{i+1}.png\")\n",
        "    reco_path = os.path.join(output_dir, f\"reconstructed_{i+1}.png\")\n",
        "    \n",
        "    # Original image\n",
        "    img = (originals[i] * 255).astype('uint8')\n",
        "    Image.fromarray(img, mode='L').save(orig_path)\n",
        "    \n",
        "    # Reconstructed image\n",
        "    img2 = (np.clip(recos[i], 0, 1) * 255).astype('uint8')\n",
        "    Image.fromarray(img2, mode='L').save(reco_path)\n",
        "    \n",
        "    print(f\"  Saved: {orig_path}\")\n",
        "    print(f\"  Saved: {reco_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print final model outputs\n",
        "print(\"\\n----------------------------------------------\")\n",
        "print(\"MODEL 1: BASELINE AUTOENCODER (TEXTBOOK VERSION)\")\n",
        "print(\"----------------------------------------------\")\n",
        "print(f\"Final Training Loss: {final_train_loss:.6f}\")\n",
        "print(f\"Final Test Reconstruction Loss: {test_loss:.6f}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
